# -*- coding: utf-8 -*-
"""Tutorial_Helper_Functions

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lFtS1jvWfpsK_sfgpMnRGlnwm8jMER3m
"""

# imports 
import tensorflow as tf
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt 
import os
from matplotlib.pyplot import imread
import pickle
from itertools import product 
import cv2
import random 
import keras
import seaborn as sns
from collections import defaultdict 
from tqdm import tqdm 
import torch
from skimage.io import imshow
import logging; logging.basicConfig(level=logging.INFO)  


# dictionary for easier handling: integers to absolute attributes
dict_nb_to_colours= {0: 'dark blue', 1: 'green', 2: 'red',  3: 'baby blue',  4: 'grey', 5: 'light blue'}

# function to summarize datasets
def summarize_imported_dataset_on_object_level(d):     
  print("There are",len(d), "training examples")
  print("with the following information:",list(d[0].keys()))
  x = ['object_image'] 
  y = ["color","shape"] 
  print("For the attribute color there are",len(set([x["color"] for x in d])),"possible values")
  print("For the attribute shape there are",len(set([x["shape"] for x in d])),"possible values")

# function to visualize examples
def visualize_example(example):

  # put this at the beginning: 
  fig,axs = plt.subplots(1,2)

  axs[0].title.set_text('Original Image')
  axs[0].imshow(example["original_image"], interpolation='none')
  axs[1].title.set_text('Image of Detected Object')
  axs[1].imshow(example["object_image"], interpolation='none')
  plt.show()
  print('Position of the object center in original image:',example['object_center'])
  print("Ground truth of the object's color:",dict_nb_to_colours[example['color']])
  print("Ground truth of the object's shape:",example['shape'])

# creation of training and test datasets
def from_bounding_boxes_list_to_ds_training_and_test(dataset,batch_size,split_thr,col_to_reshape,resize_shape): 
  # put data into a df for better handling 
  df = pd.DataFrame(dataset)  

  # rescale images to a certin image size since detector might output different sizes 
  df["object_image_rescaled"] = df[col_to_reshape].apply(lambda x: cv2.resize(x, dsize=resize_shape, interpolation=cv2.INTER_CUBIC))

  # determine ids for training +test set
  split_samples = int(len(df)*split_thr) 
  print("we split after",split_samples,"samples into train + test")

  # focus on the columns that are important + transform the selected data into a tensorflow Dataset
  img_name =  df['image_name'].to_list()
  features_img = df['object_image_rescaled'].to_list()
  obj_center = df["object_center"].apply(lambda x: list(x)).to_list()
  labels_shape = df['shape'].apply(lambda x: 6 if x =="circle" else 7).to_list() # for easier handling
  labels_color = df['color'].to_list()


  ds_train = tf.data.Dataset.from_tensor_slices((img_name[:split_samples],features_img[:split_samples],labels_shape[:split_samples],labels_color[:split_samples],obj_center[:split_samples])).batch(batch_size) 
  ds_test = tf.data.Dataset.from_tensor_slices((img_name[split_samples:],features_img[split_samples:],labels_shape[split_samples:],labels_color[split_samples:],obj_center[split_samples:])).batch(batch_size)

  print("Tensorflow Dataset for LTN is prepared")
  return ds_train,ds_test


# simple CNN and Keras models
class CNN_simple(tf.keras.Model):

  def __init__(self,n_classes,img_size=[36,36]):  
    super().__init__()
    self.rescaling = tf.keras.layers.Rescaling(1./255, input_shape=(img_size[0], img_size[1], 3))
    self.l1 = tf.keras.layers.Conv2D(16, 3, padding='same', activation='relu')
    self.l2 = tf.keras.layers.MaxPooling2D()  
    self.l3 = tf.keras.layers.Conv2D(32, 3, padding='same', activation='relu')
    self.l4 = tf.keras.layers.MaxPooling2D()
    self.l5 = tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu')
    self.l6 = tf.keras.layers.MaxPooling2D()
    self.flatten = tf.keras.layers.Flatten()
    self.l7 = tf.keras.layers.Dense(128, activation='relu')
    self.classifier = tf.keras.layers.Dense(n_classes)

  def call(self, inputs):
    x = self.rescaling(inputs)
    x = self.l1(x)
    x = self.l2(x)
    x = self.l3(x)
    x = self.l4(x)
    x = self.l5(x)
    x = self.l6(x)
    x = self.flatten(x)
    x = self.l7(x)
    return self.classifier(x)

class Simple_keras_with_concatentation_left_of(tf.keras.Model):    
    """For more info on how to use tf.keras.Model:
    https://www.tensorflow.org/api_docs/python/tf/keras/Model"""
    def __init__(self):
        super(Simple_keras_with_concatentation_left_of, self).__init__()
        self.flatten = tf.keras.layers.Flatten()
        self.dense1 = tf.keras.layers.Dense(5, activation=tf.nn.elu)
        self.dense2 = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) # returns one value in [0,1]
    def call(self, inp):
        x1, x2 = inp[0]/150, inp[1] /150
        concat_layer=  tf.concat([x1,x2],axis=-1) 
        x = self.flatten(concat_layer)
        x = self.dense1(x)
        res  = self.dense2(x)
        return res

class Simple_keras_with_concatentation_most_left(tf.keras.Model):  
    """For more info on how to use tf.keras.Model:
    https://www.tensorflow.org/api_docs/python/tf/keras/Model"""
    def __init__(self):
        super(Simple_keras_with_concatentation_most_left, self).__init__()
        self.flatten = tf.keras.layers.Flatten()
        self.dense1 = tf.keras.layers.Dense(5, activation=tf.nn.elu)
        self.dense2 = tf.keras.layers.Dense(1, activation=tf.nn.sigmoid) # returns one value in [0,1]
    def call(self, inp):
        x1, x2 = inp[0]/150, inp[1] /150
        concat_layer=  tf.concat([x1, x2],axis=1) 
        x = self.flatten(concat_layer) 
        x = self.dense1(x)
        res = self.dense2(x)
        return res

